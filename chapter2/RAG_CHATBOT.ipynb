{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMJ9ekkvEUEu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "YFwEtEywFMyk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "!pip install python-dotenv langchain_openai langchain-chroma pypdf langchain langchain_community"
   ],
   "metadata": {
    "id": "D30-rQcaFNKg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •"
   ],
   "metadata": {
    "id": "IdkiW2bzFTBg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"/content/.env\")\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "bI6E-RasFUDd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **2024 ë¶€ë™ì‚° ë³´ê³ ì„œ RAG ì±—ë´‡**"
   ],
   "metadata": {
    "id": "a_lk1ayeFVyE",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_opneai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory"
   ],
   "metadata": {
    "id": "tFzGvWaAFYwT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **PDF ë¬¸ì„œ ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• **"
   ],
   "metadata": {
    "id": "F69Oqc2jG5R1",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "loader = PyPDFLoader(\"pdf ê²½ë¡œ\")\n",
    "# PDF íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ\n",
    "documents = loader.load()\n",
    "# í…ìŠ¤íŠ¸ ë¶„í•  ì„¤ì •: ì²­í¬ í¬ê¸°ì™€ ê²¹ì¹© ì„¤ì •\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• \n",
    "chunks = text_splitter.split_documents(documents)\n",
    "# ë¶„í• ëœ ì²­í¬ ìˆ˜ í™•ì¸\n",
    "print('ë¶„í• ëœ ì²­í¬ì˜ ìˆ˜:', len(chunks))"
   ],
   "metadata": {
    "id": "2Uizi7T8G7n0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ì„ë² ë”© ìƒì„± ë° Chroma ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥**"
   ],
   "metadata": {
    "id": "Uvqz5_TVH55W",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ì„ë² ë”© ìƒì„± ë° Chroma ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥\n",
    "# OpenAIì˜ ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "persist_directory = \"í¬ë¡œë§ˆ DB ì €ì¥ ê²½ë¡œ\"\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embedding_function,\n",
    "    # DB ì €ì¥ ê²½ë¡œ\n",
    "    persist_directory=persist_directory,\n",
    ")\n",
    "\n",
    "print('ë¬¸ì„œì˜ ìˆ˜:', vectorstore._collection.count())"
   ],
   "metadata": {
    "id": "BOWnalI3H6oN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ê²€ìƒ‰ ë° ì¬ì •ë ¬**"
   ],
   "metadata": {
    "id": "hWcgxSPBJHGq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ë¦¬íŠ¸ë¦¬ë²„ ìƒì„±\n",
    "# ìƒìœ„ 3ê°œì˜ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì„¤ì •\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ],
   "metadata": {
    "id": "0yjF9T3lJH2G",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •: ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ìœ„í•œ í…œí”Œë¦¿\n",
    "template = \"\"\"ë‹¹ì‹ ì€ KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "\"\"\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = ChatPromptTempalte.from_messages(\n",
    "    [\n",
    "        (\"system\", template),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# AI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ],
   "metadata": {
    "id": "eH4Yxx0fwWCQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(prompt.format(context=\"ì»¨í…ìŠ¤íŠ¸ ì˜ˆì‹œ\"), chat_history=[\"ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ1\", \"ëŒ€í™” ê¸°ë¡ ì˜ˆì‹œ2\"], question=\"ì§ˆë¬¸ ì˜ˆì‹œ\")"
   ],
   "metadata": {
    "id": "2WNZpgi4xoZl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ë¬¸ì„œ í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ ì •ì˜**"
   ],
   "metadata": {
    "id": "PkEQer-5HhDo",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "  # ë¬¸ì„œë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°\n",
    "  return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„±: ê²€ìƒ‰í•œ ë¬¸ì„œë¥¼ í”„ë¡¬í”„íŠ¸ì— ì—°ê²°í•˜ê³  ëª¨ë¸ì„ í†µí•´ ì‘ë‹µ ìƒì„±\n",
    "chain = (\n",
    "    # ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì—°ê²°í•˜ì—¬ ì „ë‹¬\n",
    "    RunnablePassthrough.assign(\n",
    "        context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    # ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    | StrOutputParser()\n",
    ")"
   ],
   "metadata": {
    "id": "ar6rMJ91HiWw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ëŒ€í™” ê¸°ë¡ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ë©”ëª¨ë¦¬ ì„¤ì •**"
   ],
   "metadata": {
    "id": "8G1E5C3rJI1k",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    # ì„¸ì…˜ IDë³„ ëŒ€í™”ê¸°ë¡ ìƒì„±\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")"
   ],
   "metadata": {
    "id": "cMV7D2_VJKMC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜ ì •ì˜**"
   ],
   "metadata": {
    "id": "it8Ye3RWLaH2",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def chat_with_bot():\n",
    "  session_id = \"user_session\"\n",
    "  print(\"KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì±—ë´‡ì…ë‹ˆë‹¤. ì§ˆë¬¸í•´ ì£¼ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ì…ë ¥)\")\n",
    "\n",
    "  while True:\n",
    "    user_input = input(\"ì‚¬ìš©ì: \")\n",
    "\n",
    "    if user_input.lower() == 'quit':\n",
    "      break\n",
    "\n",
    "    # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”°ë¼ chain_with_memoryë¥¼ í†µí•´ ì‘ë‹µ ìƒì„±\n",
    "    response = chain_with_memory.invoke(\n",
    "        {\"question\": user_input},\n",
    "        {\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    print(\"ì±—ë´‡:\", response)"
   ],
   "metadata": {
    "id": "MZd3yQnfLfOl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **ìŠ¤íŠ¸ë¦¼ë¦¿ ì ìš©**"
   ],
   "metadata": {
    "id": "BtVzBNmLNcAs",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "%%capture --no-stderr\n",
    "!pip install streamlit pyngrok"
   ],
   "metadata": {
    "id": "z_NAC0duNeIh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ngrok ì¸ì¦í‚¤ ì„¤ì •\n",
    "!ngrok config add-authtoken ì¸ì¦í‚¤"
   ],
   "metadata": {
    "id": "FbDfFN72y77w",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **app.py**"
   ],
   "metadata": {
    "id": "TfaAqoVYzaKJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableWithMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"/content/.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# PDF ì²˜ë¦¬ í•¨ìˆ˜\n",
    "@st.cache_resource\n",
    "def process_pdf():\n",
    "  loader = PyPDFLoader(\"PDF ê²½ë¡œ\")\n",
    "  documents = loader.load()\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "  return text_splitter.split_documents(documents)\n",
    "\n",
    "# ë²¡í„° ì €ì¥ì†Œ ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def initialize_vectorstore():\n",
    "  chunks = process_pdf()\n",
    "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "  return Chroma.from_documents(chunks, embeddings)\n",
    "\n",
    "# ì²´ì¸ ì´ˆê¸°í™”\n",
    "@st.cache_resource\n",
    "def initialize_chain():\n",
    "  vertorstore = initialize_vectorstore()\n",
    "  retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "  template = \"\"\"ë‹¹ì‹ ì€ KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "  ì»¨í…ìŠ¤íŠ¸: {context}\n",
    "  \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", template),\n",
    "      (\"placeholder\", \"{chat_history}\"),\n",
    "      (\"human\", \"{question}\")\n",
    "  ])\n",
    "\n",
    "  model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0, openai_api_key=api_key)\n",
    "\n",
    "  def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "  base_chain = (\n",
    "      RunnablePassthrough.assign(\n",
    "          context=lambda x: format_docs(retriever.invoke(x[\"question\"]))\n",
    "      )\n",
    "      | prompt\n",
    "      | model\n",
    "      | StrOutputParser(0)\n",
    "  )\n",
    "\n",
    "  return RunnableWithMessageHistory(\n",
    "      base_chain,\n",
    "      lambda session_id: ChatMessageHistory()\n",
    "      input_messages_key=\"question\",\n",
    "      history_messages_key=\"chat_history\"\n",
    "  )\n",
    "\n",
    "# Streamlit UI\n",
    "def main():\n",
    "  st.set_page_config(page_title=\"KB ë¶€ë™ì‚° ë³´ê³ ì„œ ì±—ë´‡\", page_icon=\"ğŸ \")\n",
    "  st.title(\"ğŸ  KB ë¶€ë™ì‚° ë³´ê³ ì„œ AI ì–´ë“œë°”ì´ì €\")\n",
    "  st.caption(\"2024 KB ë¶€ë™ì‚° ë³´ê³ ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ\")\n",
    "\n",
    "  # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”\n",
    "  if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "  # ì±„íŒ… ê¸°ë¡ í‘œì‹œ\n",
    "  for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "      st.markdown(message[\"content\"])\n",
    "\n",
    "  # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬\n",
    "  if prompt := st.chst_input(\"ë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.\"):\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ\n",
    "    with st.chat_message(\"user\"):\n",
    "      st.markdown(prompt)\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    # ì²´ì¸ ì´ˆê¸°í™”\n",
    "    chain = initialize_chain()\n",
    "\n",
    "    # AI ì‘ë‹µ ìƒì„±\n",
    "    with st.chat_message(\"assistant\"):\n",
    "      with st.spinner(\"ë‹µë³€ ìƒì„± ì¤‘...\"):\n",
    "        response = chain.invoke(\n",
    "            {\"question\": prompt},\n",
    "            {\"configurable\": {\"session_id\": \"streamlit_session\"}}\n",
    "        )\n",
    "\n",
    "        st.markdown(response)\n",
    "\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "C3u5TbQOzblH",
    "outputId": "c894ba8e-7c82-4196-e789-6f49efe98aa1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (ipython-input-50788963.py, line 67)",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"/tmp/ipython-input-50788963.py\"\u001B[0;36m, line \u001B[0;32m67\u001B[0m\n\u001B[0;31m    lambda session_id: ChatMessageHistory()\u001B[0m\n\u001B[0m                       ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ]
  }
 ]
}