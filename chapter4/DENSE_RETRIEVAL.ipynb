{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **사전 준비**"
   ],
   "metadata": {
    "id": "faq6KwTYkM_c",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ],
   "metadata": {
    "id": "X_URMrAnkRVN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "YrI9EuCxkRp0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "byUl3JjMkTRf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"파일 경로\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "docs = loader.load_and_split(doc_splitter)"
   ],
   "metadata": {
    "id": "Jrxf9AKekrrv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **리트리버 구축**"
   ],
   "metadata": {
    "id": "pLpYJSPA4AU3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# OpenAI의 임베딩 모델 사용\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ],
   "metadata": {
    "id": "Y6VHjo7v4B2O",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS DB 생성 후 저장\n",
    "faiss_store = FAISS.from_documents(docs, embeddings)\n",
    "faiss_store.save_local(\"/content/DB\")"
   ],
   "metadata": {
    "id": "iAlLgbqy4O9S",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 저장된 DB 경로 지정 후 DB 로드\n",
    "persist_directory = \"/content/DB\"\n",
    "\n",
    "# allow_dangerous_deserialization=True\n",
    "# FAISS는 내부적으로 Pickle 파일(index.pkl) 을 로드\n",
    "# pickle은 임의의 Python 객체를 복원하는 방식이기 때문에 보안 위험이 있다\n",
    "# LangChain에서는 기본적으로 이 옵션이 꺼져 있다\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"
   ],
   "metadata": {
    "id": "abQiXpq14m7v",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# FAISS 리트리버 생성\n",
    "faiss_retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ],
   "metadata": {
    "id": "5Va0UsBK51AC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **질의**"
   ],
   "metadata": {
    "id": "4WHpwZXO6Olf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 관련 있는 문서 수집 후 챗 GPT로 최종 답변까지 수행\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0.2, model=\"gpt-4o\")\n",
    "    chain_type=\"stuff\"\n",
    "    retriever=faiss_retriever,\n",
    "    return_source_documents=True,\n",
    ")"
   ],
   "metadata": {
    "id": "dp7PjDDT6QUn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "qa_chain.invoke(\"이 회사가 발행한 주식의 총 발행량이 어느 정도야?\")"
   ],
   "metadata": {
    "id": "jkXQ4hZD6tOJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}