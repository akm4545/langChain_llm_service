{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1c5ANGKMjsK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pip install langchain langchain_openai langchain_community chromadb"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "w5kBXQSfMrXk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "l_RG9AtDMuEC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **초기 세팅**"
   ],
   "metadata": {
    "id": "1d3tVqgLMx2K",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 문서 로더 설정\n",
    "loaders = [TextLoader(\"문서 경로\")]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "  docs.extend(loader.load())"
   ],
   "metadata": {
    "id": "YRjmI74dM0D9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 문서 생성을 위한 텍스트 분할기 정의\n",
    "recursive_spliiter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "\n",
    "# 문서 분할\n",
    "split_docs = recursive_splitter.split_documents(docs)\n",
    "\n",
    "# OpenAIEmbeddings 인스턴스 생성\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Chroma vectorstore 생성\n",
    "vectorstore = Chroma.from_document(documents=split_docs, embedding=embeddings)\n",
    "\n",
    "# Chroma vectorstore 기반 리트리버 생성\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "id": "uGTZvLCYNP4z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **가상 문서 생성 체인**"
   ],
   "metadata": {
    "id": "BxjNsv7tUHwT",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 1. 가상 문서 생성 체인\n",
    "def create_virtual_doc_chain():\n",
    "  system = \"당신은 고도로 숙련된 AI입니다.\"\n",
    "  user = \"\"\"\n",
    "  주어진 질문 '{query}'에 대해 직접적으로 답변하는 가상의 문서를 생성하세요.\n",
    "  문서의 크기는 {chunk_size} 글자 언저리여야 합니다.\n",
    "  \"\"\"\n",
    "\n",
    "  prompt = ChatPromptTemplate.from_messages([\n",
    "      (\"system\", system),\n",
    "      (\"human\", user)\n",
    "  ])\n",
    "  llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "  return prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "id": "pmo22L__UJzH",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. 문서 검색 체인\n",
    "def create_retrieval_chain():\n",
    "  return RunnableLambda(lambda x: retriever.get_relevant_documents(x['virtual_doc']))\n",
    "\n",
    "# 유틸리티 함수\n",
    "def format_docs(docs):\n",
    "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ],
   "metadata": {
    "id": "iekpfhPQVG7n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 3. 최종 응답 생성 체인\n",
    "def create_final_response_chain():\n",
    "  final_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "  다음 정보와 질문을 바탕으로 답변해주세요:\n",
    "  컨텍스트: {context}\n",
    "\n",
    "  질문: {question}\n",
    "\n",
    "  답변:\n",
    "  \"\"\")\n",
    "\n",
    "  final_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.2)\n",
    "\n",
    "  return final_prompt | final_llm"
   ],
   "metadata": {
    "id": "6B6goxhvVjth",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def print_input_output(input_data, output_data, step_name):\n",
    "  print(f\"\\n--- {step_name} ---\")\n",
    "  print(f\"Input: {input_data}\")\n",
    "  print(f\"Output: {output_data}\")\n",
    "  print(\"-\" * 50)"
   ],
   "metadata": {
    "id": "ENbhY-10X-b6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_pipeline_with_logging():\n",
    "  virtual_doc_chain = create_virtual_doc_chain()\n",
    "  retrieval_chain = create_retrieval_chain()\n",
    "  final_response_chain = create_final_response_chain()\n",
    "\n",
    "  # 가상 문서 생성 단계\n",
    "  def virtual_doc_step(x):\n",
    "    result = {\"virtual_doc\": virtual_doc_chain.invoke({\n",
    "        \"query\": x[\"question\"],\n",
    "        \"chunk_size\": 200\n",
    "    })}\n",
    "    print_input_output(x, result, \"Virtual Doc Generation\")\n",
    "\n",
    "    return {**xm **result}\n",
    "\n",
    "  # 문서 검색 단계\n",
    "  def retrieval_step(x):\n",
    "    result = {\"retrieved_docs\": retrieval_chain.invoke(x)}\n",
    "    print_input_output(x, result, \"Document Retrieval\")\n",
    "\n",
    "    return {**x, **result}\n",
    "\n",
    "  # 컨텍스트 포매팅 단계\n",
    "  def context_formatting_step(x):\n",
    "    result = {\"context\": format_docs(x[\"retrieved_docs\"])}\n",
    "    print_input_output(x, result, \"Context Formatting\")\n",
    "\n",
    "    return {**x, **result}\n",
    "\n",
    "  # 최종 응답 생성 단계\n",
    "  def final_response_step(x):\n",
    "    result = final_response_chain.invoke(x)\n",
    "    print_input_output(x, result, \"Final Response Generation\")\n",
    "\n",
    "    return result\n",
    "\n",
    "  # 전체 파이프라인 구성\n",
    "  pipeline = (\n",
    "      RunnableLambda(virtual_doc_step)\n",
    "      | RunnableLambda(retrieval_step)\n",
    "      | RunnableLambda(context+formatting_step)\n",
    "      | RunnableLambda(final_response_step)\n",
    "  )\n",
    "\n",
    "  return pipeline\n",
    "\n",
    "# 파이프라인 객체 생성\n",
    "pipeline = create_pipeline_with_logging()"
   ],
   "metadata": {
    "id": "JU8I1O1MYlpS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}