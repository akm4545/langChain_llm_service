{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **사전 준비**"
   ],
   "metadata": {
    "id": "Ov4JJ-cU70vR",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ],
   "metadata": {
    "id": "pbsKdxEq73RC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "672d4hZY74v1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "gM9LbRRv76BY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"파일 경로\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)\n",
    "docs = loader.load_and_split(doc_splitter)"
   ],
   "metadata": {
    "id": "HligWCXjPtrJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# FAISS 벡터 스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)\n",
    "\n",
    "# 저장란 FAISS DB 불러오기\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserialization=True)"
   ],
   "metadata": {
    "id": "7plyTC56QUx6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **리랭킹 알고리즘**"
   ],
   "metadata": {
    "id": "W4gAoXovR1Ul",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpneAI\n",
    "from sentence_transformers import CrossEncoder\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA"
   ],
   "metadata": {
    "id": "h8LfbukVR6hp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ms-marco-MiniLM-L-12-v2 모델 다운로드\n",
    "crossencoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')"
   ],
   "metadata": {
    "id": "BxbqyzcWSi5K",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Retriever_with_cross_encoder(BaseRetriever):\n",
    "  vectorstore: Any = Field(description=\"초기 검색을 위한 벡터 저장소\")\n",
    "  crossencoder: Any = Field(description=\"재순위화를 위한 크로스 인코더 모델\")\n",
    "  k: int = Field(default=5, description=\"초기에 검색할 문서 수\")\n",
    "  rerank_top_k: int = Field(default=2, description=\"재순위화 후 최종적으로 반환할 문서 수\")\n",
    "\n",
    "  class Config:\n",
    "    arbitrary_types_allowed = True\n",
    "\n",
    "  def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "    # 초기 검색\n",
    "    initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "\n",
    "    # 인코더용 쌍 준비\n",
    "    pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "\n",
    "    # 인코더 점수 획득\n",
    "    scores = self.crossencoder.predict(pairs)\n",
    "\n",
    "    # 점수별 문서 정렬\n",
    "    scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 상위 재순위와 문서 반환\n",
    "    return [doc for doc, _ in scored_docs[:self.rerank_top_k]]"
   ],
   "metadata": {
    "id": "Wx9fVH-pS2FY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **리랭킹 알고리즘 문서 검색**"
   ],
   "metadata": {
    "id": "YmJy9tkHWA6Z",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 크로스 인코더 기반 리트리버 인스턴스 생성\n",
    "cross_encoder_retriever = Retriever_with_cross_encoder(\n",
    "    vectorstore=vectordb,\n",
    "    crossencoder=crossencoder,\n",
    "    # 초기 밀집 검색으로 반환할 문서 수 설정\n",
    "    k=4,\n",
    "    # 리랭킹을 통해 최종적으로 반환할 문서 수 설정\n",
    "    rerank_top_k=2\n",
    ")\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")"
   ],
   "metadata": {
    "id": "NBEkt_hpWilI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RetrievalQA 체인 인스턴스 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {result['result']}\")\n",
    "print(\"\\n답변 근거 문서:\")\n",
    "\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "  print(f\"\\nDocument {i+1}:\")\n",
    "  # 각 문서 출력\n",
    "  print(doc.page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {result['result']}\")\n",
    "print(\"\\n답변 근거 문서:\")\n",
    "\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "  print(f\"\\nDocument {i+1}:\")\n",
    "  # 각 문서 출력\n",
    "  print(doc.page_content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\n질문: {query}\")\n",
    "print(f\"답변: {result['result']}\")\n",
    "print(\"\\n답변 근거 문서:\")\n",
    "\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "  print(f\"\\nDocument {i+1}:\")\n",
    "  # 각 문서 출력\n",
    "  print(doc.page_content)"
   ],
   "metadata": {
    "id": "hbVwu-I9qEgl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}