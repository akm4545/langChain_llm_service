{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **사전 준비**"
   ],
   "metadata": {
    "id": "b6Op7P5QU2g7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ],
   "metadata": {
    "id": "4jNdUw1jU5Wv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "SwWo-Jm3U9MX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "vp21DPdTU-6b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"/content/drive/MyDrive/langchain-tutorial/Ch04. Advanced Rag/Data/투자설명서.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n",
    "\n",
    "docs = loader.load_and_split(doc_splitter)"
   ],
   "metadata": {
    "id": "HetBc8NhVBeg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embeddings-3-large\")"
   ],
   "metadata": {
    "id": "sParRaP-VIvn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# FAISS 라이브러리 임포트\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# FAISS 벡터 스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)"
   ],
   "metadata": {
    "id": "cZ2h4ZXbVZbK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 저장한 FAISS DB 불러오기\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserializtion=True)"
   ],
   "metadata": {
    "id": "UtztkfN-VseT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate\n",
    "from langchain.docsstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from textwrap import dedent\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ],
   "metadata": {
    "id": "YvLZ7XTv1aDY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **함수 정의**"
   ],
   "metadata": {
    "id": "NLXnqSB82yfb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class RelevanceScore(BaseModel):\n",
    "  relevance_score: float = Field(description=\"문서가 쿼리와 얼마나 관련이 있는지를 나타내는 점수.\")\n",
    "\n",
    "def reranking_documents(query: str, docs: List[Document], top_n: int = 2) ->\n",
    "List[Document]:\n",
    "  parser = JsonOutputParser(pydantic_object=RelevanceScore)\n",
    "  human_message_prompt = PromptTemplate(\n",
    "      template = \"\"\"\n",
    "      1점부터 10점까지 점수를 매겨, 다음 문서가 질문이 얼마나 관련이 있는지 평가해주세요.\n",
    "      단순히 키워드가 일치하는 것이 아니라 쿼리의 구체적인 맥락과 의도를 고려하세요.\n",
    "      {format_instructions}\n",
    "      question: {query}\n",
    "      document: {doc}\n",
    "      relevance_score:\"\"\",\n",
    "      input_variables=[\"query\", \"docs\"],\n",
    "      partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "  )\n",
    "\n",
    "  llm = ChatOpenAI(temparature=0, model_name=\"gpt-4o\", max_tokens=3000)\n",
    "  chain = human_message_prompt | llm | parser\n",
    "  scored_docs = []\n",
    "\n",
    "  for doc in docs:\n",
    "    input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "\n",
    "    try:\n",
    "      score = chain.invoke(input_data)['relevance_score']\n",
    "      score = float(score)\n",
    "    except Exception as e:\n",
    "      print(f\"오류 발생: {srt(e)}\")\n",
    "      # 기본 점수를 5점으로 설정\n",
    "      default_score = 5\n",
    "      print(f\"기본 점수 {default_score}점을 사용합니다.\")\n",
    "      score = default_score\n",
    "\n",
    "    scored_docs.append((doc, score))\n",
    "\n",
    "  reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  return [doc for doc, _ in reranked_docs[:top_n]]"
   ],
   "metadata": {
    "id": "1q_WTduX20VC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **문서 리랭킹**"
   ],
   "metadata": {
    "id": "Mah8_dMT8FEW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "query = \"이 회사의 2022년 영업손실이 정확히 얼마야?\"\n",
    "initial_docs = vectordb.similarity_search(query, k=4)\n",
    "reranked_docs = reranking_documents(query, initial_docs)"
   ],
   "metadata": {
    "id": "cYFij7-p8Hv_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 4개의 초기 검색 결과 출력\n",
    "print(f\"Query: {query}\\n\\n\")\n",
    "\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs):\n",
    "  print(f\"\\nDocument {i+1}:\")\n",
    "  print(doc.page_content)\n",
    "\n",
    "# 리랭킹 결과 출력\n",
    "print(\"\\n\\nTop reranked documents:\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "  print(f\"\\nDocument {i+1}:\")\n",
    "  # 각 문서 출력\n",
    "  print(doc.page_content)"
   ],
   "metadata": {
    "id": "d1ROmYFF8qCx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **리랭킹 RAG**"
   ],
   "metadata": {
    "id": "uOHVN9Do-M4F",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# CustomRetriever 체인을 생성\n",
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "  vectorstore: Any = Field(description=\"Retriaval을 위한 벡터 저장소\")\n",
    "\n",
    "  class Config:\n",
    "    arbitrary_types_allowed = True\n",
    "\n",
    "  # num_docs 파라미터로 리랭킹 후 반환할 최종 문서의 수를 정의\n",
    "  def get_relevant_documents(self, query:str, num_docs=2) -> List[Document]:\n",
    "    initial_docs = self.vectorstore.similarity_search(query, k=4)\n",
    "\n",
    "    return reranking_documents(query, initial_docs, top_n=num_docs)"
   ],
   "metadata": {
    "id": "JI4-tZBa-OjE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **체인 구성**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CustomRetriever 인스턴스 생성\n",
    "custom_retriever = CustomRetriever(vectorstore=vectordb)\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpneAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"이 회사의 2022년 영업손실이 정확히 얼마야?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **체인 구성**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CustomRetriever 인스턴스 생성\n",
    "custom_retriever = CustomRetriever(vectorstore=vectordb)\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpneAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"이 회사의 2022년 영업손실이 정확히 얼마야?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **체인 구성**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# CustomRetriever 인스턴스 생성\n",
    "custom_retriever = CustomRetriever(vectorstore=vectordb)\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpneAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"이 회사의 2022년 영업손실이 정확히 얼마야?\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **체인 구성**"
   ],
   "metadata": {
    "id": "f9bIXOPSx2es",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# CustomRetriever 인스턴스 생성\n",
    "custom_retriever = CustomRetriever(vectorstore=vectordb)\n",
    "\n",
    "# 답변용 LLM 인스턴스 생성\n",
    "llm = ChatOpneAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "id": "vzDSlWHOx5G_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "qa_chain.invoke(\"이 회사의 2022년 영업손실이 정확히 얼마야?\")"
   ],
   "metadata": {
    "id": "BHqOZZv3ygEr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}