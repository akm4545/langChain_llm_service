{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **사전 준비**"
   ],
   "metadata": {
    "id": "74p_jn0y15q6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install langchain langchain_openai langchain_community pypdf faiss-cpu"
   ],
   "metadata": {
    "id": "olkRaTZx18Ul",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# 먼저 구글 드라이브 마운트\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "GQ2-ANXO1-AR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")\n",
    "\n",
    "# 환경 변수에서 API 키 가져오기\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "id": "ikIGhdPX1_IU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "file_path = (\n",
    "    \"/content/drive/MyDrive/langchain-tutorial/Ch04. Advanced Rag/Data/투자설명서.pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "doc_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap = 100)\n",
    "\n",
    "docs = loader.load_and_split(doc_splitter)"
   ],
   "metadata": {
    "id": "uWfc6SnK2CDP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# 데이터를 임베딩으로 변환\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# FAISS 벡터 스토어 생성\n",
    "faiss_store = FAISS.from_documents(docs, embedding)\n",
    "\n",
    "# FAISS 벡터 스토어 저장\n",
    "persist_directory = \"/content/DB\"\n",
    "faiss_store.save_local(persist_directory)\n",
    "\n",
    "# 저장한 FAISS DB 불러오기\n",
    "vectordb = FAISS.load_local(persist_directory, embeddings=embedding, allow_dangerous_deserializtion=True)"
   ],
   "metadata": {
    "id": "zkVnmylR2QI1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain import PromptTemplate\n",
    "from typing import Literal"
   ],
   "metadata": {
    "id": "QdSdHPt5wYok",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **검색 필요 여부 판단 추론 파이프라인**"
   ],
   "metadata": {
    "id": "AVeIJwEvxFkI",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 출력 형식 클래스\n",
    "class RetrievalResponse(BaseModel):\n",
    "  Reasoning: str = Field(description=\"검색의 필요 여부를 추론하는 과정(2~3문장 이내)\")\n",
    "  Retrieve: Literal['Yes', 'No'] = Field(description=\"검색 필요 여부\")\n",
    "\n",
    "# 프롬프트 템플릿\n",
    "retrieval_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"\"\"\n",
    "    주어진 질문에 대해, 외부 문서를 참고하는 것이 더 나은 응답을 생성하는 데 도움이 되는지 판단해주세요. 추론 과정을 작성한 뒤, \"Yes\" 또는 \"No\"로 답하세요\n",
    "\n",
    "    다음 기준을 참고하세요:\n",
    "    1. 사실적 정보나 복잡한 주제에 대한 상세한 설명을 요구하는 질문의 경우, 검색이 도움이 될 수 있습니다.\n",
    "    2. 개인적인 의견, 창의적인 과제, 또는 간단한 계산의 경우, 일반적으로 검색이 필요하지 않습니다.\n",
    "    3. 잘 알려진 사실에 대해서도, 검색은 때때로 추가적인 맥락이나 검증을 제공할 수 있습니다.\n",
    "\n",
    "    질문: {query}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 사용할 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", max_tokens=2000, temperature=0.2)\n",
    "\n",
    "# 각 단계에 대한 LLMChain 생성\n",
    "retrieval_chain = retrieval_prompt | llm.with_structured_output(RetrievalResponse)"
   ],
   "metadata": {
    "id": "AoSdXbk5xGOS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **관련성 평가 추론 파이프라인**"
   ],
   "metadata": {
    "id": "TLhl5bs8vRI4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class RelevanceResponse(BaseModel):\n",
    "  Reasoning: str = Field(description=\"연관 문서의 관련성 평가 추론 과정(2~3문장 이내)\")\n",
    "  ISREL: Literal['Relevant', 'Irrelevant'] = Field(description=\"관련성 평가 결과\")\n",
    "\n",
    "relevance_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    당신은 제공된 연관 문서가 주어진 질문과 관련이 있는지, 그리고 질문에 답하는 데 유용한 정보를 제공하는지 판단하는 것입니다.\n",
    "    만약 연관 문서가 이 요구사항을 충족한다면 \"Relevant\"로 응답하고, 그렇지 않다면 \"Irrelevant\"로 응답하세요.\n",
    "\n",
    "    다음 예시들을 참고하세요:\n",
    "\n",
    "    예시 1:\n",
    "    질문: 지구의 자전은 무엇을 야기하나요?\n",
    "    연관 문서: 자전은 낮과 밤의 순환을 야기하며, 이는 또한 온도와 습도의 상응하는 순환을 만듭니다. 지구가 자전함에 따라 해수면은 하루에 두 번 상승하고 하강합니다.\n",
    "    Reasoning: 이 관련 문서는 지구의 자전이 낮과 밤의 순환을 야기한다고 명시적으로 언급하고 있어, 질문에 직접적으로 관련이 있습니다.\n",
    "    ISREL: Relevant\n",
    "\n",
    "    예시 2:\n",
    "    질문: 미국 하원의원 출마를 위한 나이 제한은 어떻게 되나요?\n",
    "    연관 문서: 헌법은 미국 상원 의원직을 위한 세 가지 자격 요건을 설정합니다: 나이(최소 30세),\n",
    "    미국 시민권(최소 9년), 그리고 선거 시점에 해당 상원의원이 대표하는 주의 거주자여야 합니다.\n",
    "    Reasoning: 이 관련 문서는 미국 하원이 아닌 상원 의원직에 대한 나이 제한을 논의하고 있어, 주어진 질문과 직접적인 관련이 없습니다.\n",
    "    ISREL: [Irrelevant]\n",
    "\n",
    "    위의 예시들을 참고하여, 다음 질문과 연관 문서에 대해 평가해주세요.\n",
    "\n",
    "    질문: {query}\n",
    "    연관 문서: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 사용할 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", max_tokens=2000, temperature=0.2)\n",
    "\n",
    "# 각 단계에 대한 LLMChain 생성\n",
    "relevance_chain = relevance_prompt | llm_with_structured_output(RelevanceResponse)"
   ],
   "metadata": {
    "id": "JRXkbDGGWNG7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **검색 문서 답변 생성 파이프라인**"
   ],
   "metadata": {
    "id": "n-n2FnF4vTQh",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GenerationResponse(BaseModel):\n",
    "  response: str = Field(description=\"질문과 연관 문서를 바탕으로 생성된 답변\")\n",
    "\n",
    "# 답변 생성 단계 프롬프트 템플릿\n",
    "generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    template=\"질문 '{query}'와 연관 문서 '{context}'를 기반으로 답변을 만들어주세요.\"\n",
    ")\n",
    "\n",
    "# 사용할 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", max_tokens=2000, temperature=0.2)\n",
    "generation_chain = generation_prompt | llm.with_structured_output(GenerationResponse)"
   ],
   "metadata": {
    "id": "cyCFSjyCvwRZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **지원 평가 파이프라인**"
   ],
   "metadata": {
    "id": "vHxeKZnz0rGa",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SupportResponse(BaseModel):\n",
    "  REasoning: str = Field(description=\"답변이 연관 문서에 충분히 근거하는지 여부를 추론하는 과정(2~3문장 이내)\")\n",
    "  ISSUP: Literal['Fully supported', 'Partially supported', 'No support'] =\n",
    "  Field(description=\"답변이 연관 문서에 충분히 근거하는지에 대한 평가 결과\")\n",
    "\n",
    "support_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"response\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    당신은 주어진 답변이 연관 문서의 정보에 얼마나 근거하고 있는지 평가하는 것입니다. 다음 척도를 사용하여\n",
    "    평가해주세요:\n",
    "\n",
    "    1. Fully supported - 답변의 모든 정보가 연관 문서에 의해 뒷받침되거나, 연관 문서에서 직접 추출된 경우입니다. 어느\n",
    "    답변과 연관 문서의 일부가 거의 동일한 극단적인 경우에만 해당합니다.\n",
    "    2. Partially supported - 답변이 어느 정도 연관 문서에 의해 뒷받침되지만, 연관 문서에서 다루지 않는 주요\n",
    "    정보가 답변에 포함된 경우입니다. 예를 들어, 질문이 두 가지 개념에 대해 물었는데 연관 문서가 그중 하나만 다루고\n",
    "    있다면 이에 해당합니다.\n",
    "    3. No support - 답변이 연관 문서를 완전히 무시하거나, 관련이 없거나, 또는 연관 문서와 모순되는\n",
    "    경우입니다. 연관 문서가 질문과 무관한 경우에도 이에 해당할 수 있습니다.\n",
    "\n",
    "    주의: 답변이 사실인지 아닌지를 판단하기 위해 외부 정보나 지식을 사용하지 마세요. 오직 답변이\n",
    "    연관 문서에 의해 뒷받침되는지만 확인하세요. 답변이 질문을 잘 따르고 있는지는 판단하지 않습니다.\n",
    "\n",
    "    다음 예시를 참고하세요\"\n",
    "    질문: 자연어 처리에서 단어 임베딩의 사용에 대해 설명해주세요.\n",
    "    답변: 단어 임베딩은 감성 분석, 텍스트 분류, 다음 단어 예측, 동의어와 유추 관계 이해 등의\n",
    "    작업에 유용합니다.\n",
    "    연관 문서: 단어 임베딩은 자연어 처리(NLP)에서 어휘의 단어나 구를 실수 벡터에 매핑하는 언어\n",
    "    모델링 및 특징 학습 기술의 총칭입니다. 단어와 구 임베딩은 기본 입력 표현으로 사용될 때\n",
    "    구문 분석, 감성 분석, 다음 토큰 예측, 유추 감지 등의 NLP 작업에서 성능 향상을 보여주었습니다.\n",
    "    Reasoning: 답변에서 언급된 단어 임베딩의 모든 응용 분야(감성 분석, 텍스트 분류, 다음 단어 예측,\n",
    "    동의어와 유추 관계 이해)가 연관 문서에서 직접적으로 언급되거나 유추될 수 있습니다. 따라서 답변은\n",
    "    연관 문서에 의해 완전히 뒷받침됩니다.\n",
    "    ISSUP: Fully supported\n",
    "\n",
    "    위의 예시를 참고하여, 주어진 질문, 답변, 연관 문서에 대한 당신의 평가를 제시해주세요:\n",
    "\n",
    "    질문: {query}\n",
    "    답변: {response}\n",
    "    연관 문서: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 각 단계에 대한 LLMChain 생성\n",
    "support_chain = support_prompt | llm.with_structured_output(SupportResponse)"
   ],
   "metadata": {
    "id": "H2EIEssA0sv8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **유용성 평가 파이프라인**"
   ],
   "metadata": {
    "id": "u_89QUQoQCu3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class UtilityResponse(BaseModel):\n",
    "  Reasoning: str = Field(description=\"응답의 유용성 평가 추론 과정\")\n",
    "  ISUSE: Literal[1, 2, 3, 4, 5] = Field(description=\"응답의 유용성 평가 결과\")\n",
    "\n",
    "utility_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"response\"],\n",
    "    template=\"\"\"\n",
    "    주어진 질문과 답변에 대해, 그 응답이 얼마나 도움이 되고 유익한 답변인지 1점(최저)부터 5점(최고)까지 평가해주세요.\n",
    "    이 점수를 'Utility_score'라고 부릅니다.\n",
    "\n",
    "    평가 기준은 다음과 같습니다:\n",
    "    5: 답변이 완벽하고 매우 상세하며 정보가 풍부하여 질문의 정보 요구를 완전히 충족시킵니다.\n",
    "    4: 답변이 대체로 질문의 요구를 충족시키지만, 더 자세한 정보 제공, 응답 구조 개선, 또는 일관성 향상 들의 약간의 개선이 가능합니다.\n",
    "    3: 답변이 수용 가능하지만, 사용자의 요구를 만족시키기 위해 주요한 추가 정보나 개선이 필요합니다.\n",
    "    2: 답변이 주요 요청을 다루고는 있지만, 불완전하거나 질문과 완전히 관련이 없습니다.\n",
    "    1: 답변이 거의 주제와 관련이 없거나 완전히 무관합니다.\n",
    "\n",
    "    다음 예시들을 참고하세요:\n",
    "\n",
    "    예시 1:\n",
    "    질문: 2023년 현재 영국의 총리는 누구인가요?\n",
    "    답변: Boris Johnson은 2019년부터 2022년까지 영국의 총리였습니다.\n",
    "    Reasoning: 이 응답은 2019년부터 2022년까지의 영국 총리에 대해 사실적으로 정확한 진술을 제공하지만,\n",
    "    질문은 2023년 현재의 총리를 묻고 있습니다. 따라서 질문에 직접적으로 답하지 않아 유용성이 2점입니다.\n",
    "    ISUSE: 2\n",
    "\n",
    "    예시 2:\n",
    "    질문: 여행 목적지인 도쿄, 일본에 대한 설명을 바탕으로 10개의 관광 명소를 추천하고 각각에 대해 자세히 설명해주세요.\n",
    "    답변: 도쿄는 흥미진진한 관광 명소로 가득한 활기찬 도시입니다. 꼭 봐야 할 명소로는 도쿄 스카이트리, 도쿄 디즈니랜드,\n",
    "    센소지 사원, 메이지 신궁, 츠키지 어시장, 하라주쿠, 신주쿠 교엔 등이 있습니다.\n",
    "    Reasoning: 이 응답은 각 명소에 대한 설명을 제공하지 않았고, 명소의 수도 10개보다 적습니다. 질문에\n",
    "    부분적으로 답변하고 있지만, 지시사항을 엄격히 따르지 않았습니다.\n",
    "    ISUSE: 3\n",
    "\n",
    "    위의 예시들을 참고하여, 주어진 질문과 응답에 대한 당신의 평가를 제시해주세요:\n",
    "\n",
    "    질문: {query}\n",
    "    응답: {response}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# 사용할 LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", max_tokens=2000, temperature=0.2)\n",
    "\n",
    "# 각 단계에 대한 LLMChain 생성\n",
    "utility_chain = utility_prompt | llm.with_structured_output(UtilityResponse)"
   ],
   "metadata": {
    "id": "_HxafN0eQEyv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}