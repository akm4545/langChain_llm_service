{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **사전 준비**"
   ],
   "metadata": {
    "id": "wGInD5GyJ9cc",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph\n",
    "%pip install -U langchain-openai"
   ],
   "metadata": {
    "id": "46QW2NVMJ_nG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")"
   ],
   "metadata": {
    "id": "rzILv6LiKN74",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 실습에 사용할 그래프의 상태 정의\n",
    "# TypedDict = 타입 힌트\n",
    "\n",
    "# Annotated는 런타임에 실제 동작하지 않고, 타입 검사기와 프레임워크에게 ‘설명/주석’ 역할을 하는 문법\n",
    "# → “messages는 list 타입이다 그리고 add_messages라는 규칙이 붙어 있다”\n",
    "# Python 입장에서는 단순 주석\n",
    "# LangGraph 입장에서는 병합 방식 지시\n",
    "\n",
    "class State(TypedDict):\n",
    "  messages: Annotated[list, add_messages]\n",
    "\n",
    "# 실습에서 사용할 그래프 인스턴스 생성\n",
    "graph_builder = StateGraph(State)"
   ],
   "metadata": {
    "id": "911-m755Kmre",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **챗봇 노드**"
   ],
   "metadata": {
    "id": "ljAIyhQbOgkn",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 오픈 AI 클라이언트 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 오픈AI를 호출하여 응답을 받아온 뒤 상태값에 저장하여 반환하는 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "  return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 챗봇 노드 정의\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "metadata": {
    "id": "P_0mXkcYOh_h",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# 진입 지점\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 종료 지점\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ],
   "metadata": {
    "id": "TKw866LTPR74",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "graph = graph_builder.compile()"
   ],
   "metadata": {
    "id": "XFpLnUNpPrN9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 무한 루프\n",
    "while True:\n",
    "  # 사용자의 질의 입력받기\n",
    "  # input() 함수는 사용자 입력을 기다림\n",
    "  # \"User: \" 라는 안내 문구를 보여주고 입력받은 값을 user_input 변수에 저장\n",
    "  user_input = input(\"User: \")\n",
    "\n",
    "  # 사용자가 quit 또는 exit, q를 입력한다면 루프 종료\n",
    "  if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "    print(\"Goodbye!\")\n",
    "    break\n",
    "\n",
    "  # 사용자의 입력을 그래프에 전달하여 정의된 흐름 실행\n",
    "  # graph.stream() → LangGraph 그래프 실행\n",
    "  # (\"user\", user_input) → 튜플로 “사용자가 입력했다” 표시\n",
    "  # 결괏값 event에 저장\n",
    "  # {\"messages\": (\"user\", user_input)} 정의한 State\n",
    "  for event in graph.stream({\"messages\": (\"user\", user_input)}):\n",
    "    for value in event.values():\n",
    "      print(\"Assistant:\", value[\"messages\"][-1].content)"
   ],
   "metadata": {
    "id": "nMki_roMTybE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **그래프 시각화**"
   ],
   "metadata": {
    "id": "zLbEL_f87nSf",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, dsiplay\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "metadata": {
    "id": "4gutR5Q67pFr",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Tavily 검색 엔진 세팅**"
   ],
   "metadata": {
    "id": "K7uqtYakAJgl",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U tavily-python\n",
    "%pip install -U langchain_community"
   ],
   "metadata": {
    "id": "ZYe6aspJALsS",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily 검색 엔진을 도구로 정의\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "# 호출 예시\n",
    "tool.invoke(\"내일 대한민국 서울의 날씨는?\")"
   ],
   "metadata": {
    "id": "gOnfGSptCxGX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **외부 검색 도구 노드**"
   ],
   "metadata": {
    "id": "tmLzsuh8R4Jp",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "from langchain_openai import ChatOpneAI\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# 그래프 상태 정의\n",
    "class State(TypedDict):\n",
    "  messages: Annotated[list, add_messages]\n",
    "\n",
    "# 그래프 정의\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 오픈AI 클라이언트 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# 오픈AI 클라이언트에 Tavily 검색 엔진 도구 할당\n",
    "# llm이 판별할 수 있도록 툴 정보를 바인딩\n",
    "# 툴 내부에 툴의 이름, 기능 등이 정의?\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chatbot(state: State):\n",
    "  return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# 그래프에 챗봇 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ],
   "metadata": {
    "id": "rrGWkCA4R5z4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# 도구 실행 결과를 담는 메시지\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# 도구 노드로 사용할 클래스\n",
    "class BasicToolNode:\n",
    "  # 도구 노드에서 사용할 초기 파라미터 정의\n",
    "  # -> None: = 이 함수는 값을 반환하지 않는다는 타입 힌트\n",
    "  def __init__(self, tools: list) -> None:\n",
    "    # tools를 받아 도구 이름이 키고 값이 툴인 딕셔너리 생성\n",
    "    self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "  # 도구 노드가 호출될 때의 행동 정의\n",
    "  # __call__ = 객체를 함수처럼 호출 가능 -> tool_node(inputs) -> 내부적으로 tool_node.__call__(inputs)\n",
    "  def __call__(self, inputs: dict):\n",
    "    # 입력된 상태의 가장 마지막 메시지 획득\n",
    "    # 딕셔너리에서 값을 꺼낼때 null 에러를 방지하기 위해\n",
    "    # \"messages\"가 있으면 해당 값 리턴, 없으면 [] 리턴\n",
    "    if messages := inputs.get(\"messages\", []):\n",
    "      message = messages[-1]\n",
    "    else:\n",
    "      raise ValueError(\"No message found in input\")\n",
    "\n",
    "    # 메시지의 tool_calls에 도구 정보가 존재한다면 이를 활용해 도구 호출\n",
    "    outputs = []\n",
    "\n",
    "    for tool_call in message.tool_calls:\n",
    "      tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "\n",
    "      # 도구 호출의 결과물을 ToolMessage로 정의하여 출력값에 저장\n",
    "      # 도구 결과를 다시 LLM에게 알려줘야 하기 때문에 형식을 맞춤\n",
    "      outputs.append(\n",
    "          ToolMessage(\n",
    "              # tool_result의 값을 json 문자열로 변환\n",
    "              # ensure_ascii=False = 한글 깨짐 방지 옵션\n",
    "              content=json.dumps(tool_result, ensure_ascii=False),\n",
    "              # 어떤 도구의 결과인지를 알려주기 위함\n",
    "              name=tool_call[\"name\"],\n",
    "              # 어떤 요청에 대한 응답인지 알려주기 위함\n",
    "              # 한 번에 여러 도구를 호출할 수 있기 때문에 ID로 짝 맞춤\n",
    "              tool_call_id=tool_call[\"id\"],\n",
    "          )\n",
    "      )\n",
    "\n",
    "    # 출력값을 상태값 형식에 맞춰 변환\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "# 도구 노드 정의\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# 도구 노드 그래프에 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ],
   "metadata": {
    "id": "c0rSDt9VUzDs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "\n",
    "# 도구 노드 호출 여부를 결정하는 함수 정의\n",
    "# Literal[\"tools\", \"__end__\"] -> 반환값 타입 힌트 -> tools나 __end__만 반환\n",
    "def route_tools(state: State,) ->  Literal[\"tools\", \"__end__\"]:\n",
    "  # 상태값의 가장 최근 메시지를 정의\n",
    "  # state가 list라면\n",
    "  if isinstance(state, list):\n",
    "    ai_message = state[-1]\n",
    "  # state가 딕셔너리라면 messages 추출하고 없으면 빈 리스트\n",
    "  elif messages := state.get(\"messages\", []):\n",
    "    ai_message = messages[-1]\n",
    "  else:\n",
    "    raise ValueError(f\"No messages found in input state to tool_edge {state}\")\n",
    "\n",
    "  # 가장 최근 메시지에 tool_calls 속성이 있다면 tools 노드를, 아니라면 종료 지정을 반환\n",
    "  # hasattr -> 객체에 그 이름의 속성이 있으면 true 반환\n",
    "  if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "    return \"tools\"\n",
    "\n",
    "  return \"__end__\"\n",
    "\n",
    "# 챗봇 노드에 조건부 에지를 정의\n",
    "# chatbot 노드 실행 후\n",
    "# route_tools 함수 실행\n",
    "# 반환값에 따라 다음 노드 결정\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", \"__end__\": \"__end__\"},\n",
    ")"
   ],
   "metadata": {
    "id": "J8bdy63eicVc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 도구 노드와 챗봇 노드 연결\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 진입 지점으로 챗봇 노드 지정\n",
    "graph_builder.add_edge(START, \"chatbot\")"
   ],
   "metadata": {
    "id": "YOtW2BzLqlRp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()\n",
    "# 그래프 이미지화\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "metadata": {
    "id": "Ve8t_GdurCzw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **스트리밍**"
   ],
   "metadata": {
    "id": "yKqL-tQmUTOW",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "while True:\n",
    "  # 사용자 질문 입력받기\n",
    "  user_inpur = input(\"User: \")\n",
    "  print(\"User:\", user_input)\n",
    "\n",
    "  if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "    print(\"Goodbye!\")\n",
    "    break\n",
    "\n",
    "  # 업데이트된 내용을 확인할 수 있는 그래프 스트리밍 정의\n",
    "  events = graph.stream(input={\"messages\": [(\"user\", user_input)]},\n",
    "                        stream_mode=\"updates\")\n",
    "\n",
    "  # 그래프 이벤트 내의 메시지를 출력\n",
    "  for event in events:\n",
    "    for value in event.values():\n",
    "      if isinstance(value[\"messages\"][-1], BaseMessage):\n",
    "        print(\"Assistant:\", value[\"messages\"][-1].content)"
   ],
   "metadata": {
    "id": "QC1szA0xUVEn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **상태 저장하기**"
   ],
   "metadata": {
    "id": "V7ZTn5L9YO-s",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ],
   "metadata": {
    "id": "3Am8ou6mYQhA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "  messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-40-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "  return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# 미리 빌드된 도구 노드\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# 미리 빌드된 조건부 에지\n",
    "# \"chatbot\" -> 출발 노드\n",
    "# tools_condition -> 상태를 보고 어디로 갈지 결정하는 함수\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# tools -> 시작\n",
    "# chatbot -> 도착\n",
    "# tools 실행 후 chatbot으로 돌아오라는 의미\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START -> 그래프 진입 지점\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 체크포인터를 지정하여 그래프를 컴파일\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ],
   "metadata": {
    "id": "4Rrslf74c4Tj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from iPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "metadata": {
    "id": "Rrb_fIYhzTX3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ],
   "metadata": {
    "id": "6lXiIpG7zcMi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_input = \"안녕! 내 이름은 오해원이야.\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "  event[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "id": "Gk5JXS1pzxmf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_input = \"내 이름을 기억하니?\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}\n",
    ")"
   ],
   "metadata": {
    "id": "LxjQFfEi0X-m",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    # thread_id = 2로 변경\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}},\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "  event[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "id": "BZPk4VyOzQ4r",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(snapshot)"
   ],
   "metadata": {
    "id": "KKdlsyYl1HC0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **루프 개입하기**"
   ],
   "metadata": {
    "id": "-fEPgDqV2aO8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"],\n",
    ")"
   ],
   "metadata": {
    "id": "E2sEdZaA2cOw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "user_input = \"지금 서울 날씨 어때?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]},\n",
    "    config,\n",
    "    stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "  if \"messages\" in event:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ],
   "metadata": {
    "id": "eEvTatG-KJxR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "print(snapshot.next)"
   ],
   "metadata": {
    "id": "Lo-BG_5xLFEQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **state 업데이트**"
   ],
   "metadata": {
    "id": "aAmuGjJJME4e",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "# 최근 메시지\n",
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "# 최근 메시지의 id\n",
    "existing_message_id = existing_message.tool_calls[0][\"id\"]\n",
    "\n",
    "# 강제할 응답 정의\n",
    "answer = \"서울의 날씨는 매우 맑아요.\"\n",
    "\n",
    "# 강제할 응답을 포함한 메시지 상태 정의\n",
    "new_messages = [\n",
    "    ToolMessage(content=answer, tool_call_id=existing_message_id),\n",
    "    AIMessage(content=answer)\n",
    "]\n",
    "\n",
    "# 그래프 상태를 새로 작성한 메시지 상태로 변경\n",
    "graph.update_state(\n",
    "    config,\n",
    "    {\"messages\": new_messages},\n",
    ")"
   ],
   "metadata": {
    "id": "zzEudrB4MG71",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"\\n\\nLast 2 messages;\")\n",
    "print(graph.get_state(config).values[\"messages\"][-2:])"
   ],
   "metadata": {
    "id": "eAHOGAFwM-oz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}