{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **환경 설정**"
   ],
   "metadata": {
    "id": "8k0jDFvWFYdt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture --no-stderr\n",
    "!pip install langchain_community tiktoken langchain-openai chromadb langchain langgraph"
   ],
   "metadata": {
    "id": "yfFlvQAGFawX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")"
   ],
   "metadata": {
    "id": "2nZmLnwtFppx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **문서 정의**"
   ],
   "metadata": {
    "id": "DSeb_B-FGOeb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# 크롤링할 URL 지정\n",
    "url = \"https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel\"\n",
    "\n",
    "# 해당 페이지를 재귀적으로 크롤링\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url,\n",
    "    max_depth=20,\n",
    "    extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "\n",
    "# 지정된 URL에서 크롤링한 문서를 'docs' 변수에 저장\n",
    "docs = loader.load()\n",
    "\n",
    "# 크롤링된 문서를 'source' 메타데이터를 기준으로 정렬\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "\n",
    "# 모든 문서의 내용을 하나의 문자열로 연결\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join([doc.page_content for doc in d_reversed])"
   ],
   "metadata": {
    "id": "BrQkekxZGP0Y",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **코드 생성**"
   ],
   "metadata": {
    "id": "DvtK4D1rIpaD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM이 LCEL 전문가로서 사용자의 질문에 답변하도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"\n",
    "당신은 LCEL(LangChain expression language) 전문가인 코딩 어시스턴트입니다.\n",
    "다음은 필요한 LCEL 문서 전문입니다:\n",
    "--------\n",
    "{context}\n",
    "--------\n",
    "위에 제공된 문서를 기반으로 사용자 질문에 답변하세요.\n",
    "제공하는 코드는 실행 가능해야 하며, 필요한 모든 import 문과 변수들이 정의되어 있어야 합니다.\n",
    "답변을 다음과 같은 구조로 작성하세요:\n",
    "1. prefix : 문제와 접근 방식에 대한 설명\n",
    "2. imports : 코드 블록 import 문\n",
    "3. code : import 문을 제외한 코드 블록\n",
    "4. description : 질문에 대한 코드 스키마\n",
    "\n",
    "다음은 사용자 질문입니다:\n",
    "\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자의 질문을 포함한 템플릿 작성\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 코드 출력을 구조화하기 위한 데이터 모델 정의\n",
    "class code(BaseModel):\n",
    "  prefix: str = Field(description=\"문제와 접근 방식에 대한 설명\")\n",
    "  imports: str = Field(description=\"코드 블록 import 문\")\n",
    "  code: str = Field(description=\"import 문을 제외한 코드 블록\")\n",
    "  description: str = Field(description=\"질문에 대한 코드 스키마\")\n",
    "\n",
    "# 코드 생성을 위한 LLM 정의\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 프롬프트, 구조화된 LLM 출력을 결합하여 RAG 체인 생성\n",
    "code_gen_chain = code_gen_prompt | llm.with_structured_output(code)"
   ],
   "metadata": {
    "id": "wTmSlhTEIrF3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"LCEL로 RAG 체인을 어떻게 만들어?\"\n",
    "solution = code_gen_chain.invoke(\n",
    "    {\"context\": concatenated_content, \"messages\": [(\"user\", question)]}\n",
    ")\n",
    "\n",
    "print(solution)"
   ],
   "metadata": {
    "id": "9KXSBBYRMf_D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **상태**"
   ],
   "metadata": {
    "id": "VWehvyHeHx8a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List, TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "  error: str\n",
    "  messages: List\n",
    "  generation: str\n",
    "  iterations: int"
   ],
   "metadata": {
    "id": "w02lLk8zHz_f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}