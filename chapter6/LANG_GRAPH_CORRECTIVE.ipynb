{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **환경 설정**"
   ],
   "metadata": {
    "id": "m05c1dJjVcwJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install langchain_community tiktoken langchain-openai chromadb langchain langgraph tavily-python"
   ],
   "metadata": {
    "id": "0JfkcMuwVgM7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")"
   ],
   "metadata": {
    "id": "UEhD_ErVLWiO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **벡터 DB 구축**"
   ],
   "metadata": {
    "id": "wHC6MjrRMIkS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.docment_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 크롤링할 블로그의 url 정의\n",
    "urls = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/javaguide.html\",\n",
    "    \"https://google.github.io/styleguide/jsguide.html\",\n",
    "]\n",
    "\n",
    "# WebBaseLoader를 사용하여 주어진 URL 목록에서 문서 크롤링\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "# docs에서 sublist 이름으로 하나씩 추출\n",
    "# -> sublist를 다시 item으로 추출\n",
    "# 맨 왼쪽의 최종 반환값\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# 지정한 크기만큼 텍스트를 분할하는 텍스트 분할기 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Chroma 벡터 저장소에 문서의 분할된 조각 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEnbeddings(),\n",
    ")\n",
    "\n",
    "# 벡터 저장소에서 검색을 수행할 수 있는 검색기 생성\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "id": "WdsHYoSTMKeh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **문서 평가 노드**"
   ],
   "metadata": {
    "id": "vE4OrIfxSDTD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 문서와 질문의 연관성을 평가하기 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "  binary_score: str = Field(\n",
    "      description=\"문서와 질문의 연관성 여부. (예 or 아니오)\"\n",
    "  )\n",
    "\n",
    "# 연관성 평가를 위한 LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperture=0)\n",
    "# LLM의 출력이 반드시 GradeDocuments 형태가 되도록 강제한다\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# LLM이 사용자의 질문에 대해 문서의 연관성을 평가할 수 있도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"당신은 사용자의 질문에 대해 검색된 문서의 관련성을 평가하는 전문가입니다.\n",
    "  문서에 질문과 관련된 키워드나 의미가 담겨 있으면, 해당 문서를 '관련 있음'으로 평가하세요.\n",
    "  문서가 질문과 관련이 있는지 여부를 '예' 또는 '아니오'로 표시해 주세요\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자의 질문 및 문서 내용을 포함한 템플릿 작성\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"검색된 문서: \\n\\n {document} \\n\\n 사용자 질문: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트와 구조화된 LLM 평가기를 결합하여 retrieval_grader 객체 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ],
   "metadata": {
    "id": "1Fqir6EUSF56",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"파이썬 코드 작성 가이드\"\n",
    "\n",
    "# 연관 문서 검색\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "# 검색된 문서의 연관성 평가\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ],
   "metadata": {
    "id": "YsCnCBa4XghJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **답변 생성**"
   ],
   "metadata": {
    "id": "JjXWbleuYa-d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM이 제공된 문맥을 바탕으로 답변할 수 있도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"당신은 질문에 답변하는 업무를 돕는 도우미입니다.\n",
    "제공된 문맥을 바탕으로 질문에 답변하세요. 만약 답을 모르면 모른다고 말하세요.\n",
    "세 문장을 넘지 않도록 답변을 간결하게 작성하세요.\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자의 질문 및 문서 내용을 포함한 템플릿 작성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"질문: {question} \\n 문맥: {context} \\n 답변: \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 검색된 문서들을 한 문자열로 병합\n",
    "def format_docs(docs):\n",
    "  return \"\\n\\n.join(doc.page_content for doc in docs)\"\n",
    "\n",
    "# 프롬프트, LLM, 문자열 출력을 결합하여 RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "id": "1O74oJ9mYcVY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}