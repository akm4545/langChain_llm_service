{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **환경 설정**"
   ],
   "metadata": {
    "id": "m05c1dJjVcwJ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "! pip install langchain_community tiktoken langchain-openai chromadb langchain langgraph tavily-python"
   ],
   "metadata": {
    "id": "0JfkcMuwVgM7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"/content/.env\")"
   ],
   "metadata": {
    "id": "UEhD_ErVLWiO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **벡터 DB 구축**"
   ],
   "metadata": {
    "id": "wHC6MjrRMIkS",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.docment_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 크롤링할 블로그의 url 정의\n",
    "urls = [\n",
    "    \"https://google.github.io/styleguide/pyguide.html\",\n",
    "    \"https://google.github.io/styleguide/javaguide.html\",\n",
    "    \"https://google.github.io/styleguide/jsguide.html\",\n",
    "]\n",
    "\n",
    "# WebBaseLoader를 사용하여 주어진 URL 목록에서 문서 크롤링\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "# docs에서 sublist 이름으로 하나씩 추출\n",
    "# -> sublist를 다시 item으로 추출\n",
    "# 맨 왼쪽의 최종 반환값\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# 지정한 크기만큼 텍스트를 분할하는 텍스트 분할기 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# 문서 분할\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Chroma 벡터 저장소에 문서의 분할된 조각 저장\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEnbeddings(),\n",
    ")\n",
    "\n",
    "# 벡터 저장소에서 검색을 수행할 수 있는 검색기 생성\n",
    "retriever = vectorstore.as_retriever()"
   ],
   "metadata": {
    "id": "WdsHYoSTMKeh",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **문서 평가 노드**"
   ],
   "metadata": {
    "id": "vE4OrIfxSDTD",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 문서와 질문의 연관성을 평가하기 위한 데이터 모델 정의\n",
    "class GradeDocuments(BaseModel):\n",
    "  binary_score: str = Field(\n",
    "      description=\"문서와 질문의 연관성 여부. (예 or 아니오)\"\n",
    "  )\n",
    "\n",
    "# 연관성 평가를 위한 LLM 정의\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperture=0)\n",
    "# LLM의 출력이 반드시 GradeDocuments 형태가 되도록 강제한다\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# LLM이 사용자의 질문에 대해 문서의 연관성을 평가할 수 있도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"당신은 사용자의 질문에 대해 검색된 문서의 관련성을 평가하는 전문가입니다.\n",
    "  문서에 질문과 관련된 키워드나 의미가 담겨 있으면, 해당 문서를 '관련 있음'으로 평가하세요.\n",
    "  문서가 질문과 관련이 있는지 여부를 '예' 또는 '아니오'로 표시해 주세요\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자의 질문 및 문서 내용을 포함한 템플릿 작성\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"검색된 문서: \\n\\n {document} \\n\\n 사용자 질문: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 프롬프트와 구조화된 LLM 평가기를 결합하여 retrieval_grader 객체 생성\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ],
   "metadata": {
    "id": "1Fqir6EUSF56",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"파이썬 코드 작성 가이드\"\n",
    "\n",
    "# 연관 문서 검색\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "# 검색된 문서의 연관성 평가\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ],
   "metadata": {
    "id": "YsCnCBa4XghJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **답변 생성**"
   ],
   "metadata": {
    "id": "JjXWbleuYa-d",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# LLM이 제공된 문맥을 바탕으로 답변할 수 있도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"당신은 질문에 답변하는 업무를 돕는 도우미입니다.\n",
    "제공된 문맥을 바탕으로 질문에 답변하세요. 만약 답을 모르면 모른다고 말하세요.\n",
    "세 문장을 넘지 않도록 답변을 간결하게 작성하세요.\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자의 질문 및 문서 내용을 포함한 템플릿 작성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"질문: {question} \\n 문맥: {context} \\n 답변: \"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 검색된 문서들을 한 문자열로 병합\n",
    "def format_docs(docs):\n",
    "  return \"\\n\\n.join(doc.page_content for doc in docs)\"\n",
    "\n",
    "# 프롬프트, LLM, 문자열 출력을 결합하여 RAG 체인 생성\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "id": "1O74oJ9mYcVY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 정의된 RAG 체인을 사용하여 질문과 문맥을 기반으로 답변 생성\n",
    "generation = rag_chain.invoke(\n",
    "    {\"context\": format_docs(docs), \"question\": question}\n",
    ")\n",
    "\n",
    "# 생성된 답변 출력\n",
    "print(generation)"
   ],
   "metadata": {
    "id": "-grYZ-aw57e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **질문 재작성**"
   ],
   "metadata": {
    "id": "zJIj-sQQ67Yt",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# LLM이 입력된 질문을 웹 검색에 적합한 형태로 변형하도록 지시하는 프롬프트 정의\n",
    "system = \"\"\"당신은 입력된 질문을 변형하여 웹 검색에 최적화된 형태로 만드는 질문 생성기입니다.\n",
    "입력된 질문을 보고 그 이면에 이쓴 의미나 의도를 파악해주세요.\"\"\"\n",
    "\n",
    "# 시스템 메시지와 사용자 질문을 포함한 템플릿 작성\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "   [\n",
    "       (\"system\", system),\n",
    "       (\n",
    "           \"human\", \"질문: \\n\\n {question} \\n 더 나은 질문으로 바꿔주세요.\",\n",
    "       ),\n",
    "   ]\n",
    ")\n",
    "\n",
    "# 프롬프트, LLM, 문자열 출력을 결합하여 질문 변형 체인 생성\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()"
   ],
   "metadata": {
    "id": "Y3n6hAAM6833",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "question = \"C++ 깔끔하게 짜고 싶다\"\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "metadata": {
    "id": "iaYxHCyx8DLU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **웹 검색 툴 정의**"
   ],
   "metadata": {
    "id": "Y3qncWVA9SES",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ],
   "metadata": {
    "id": "zgT8Gl9K9a9U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **상태값 정의**"
   ],
   "metadata": {
    "id": "M4_vJU9w97Fq",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "  question: str\n",
    "  generation: str\n",
    "  web_search: str\n",
    "  documents: List[str]"
   ],
   "metadata": {
    "id": "Mdomqoqf99xQ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Corrective-RAG 그래프**"
   ],
   "metadata": {
    "id": "ferSi4HN-rCi",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def retrieve(state):\n",
    "  \"\"\"\n",
    "  문서를 검색합니다\n",
    "\n",
    "  Args:\n",
    "      state (dict): 현재 그래프의 상태\n",
    "\n",
    "  Returns:\n",
    "      state (dict): 현재 문서를 포함한 새로운 상태\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"---검색---\")\n",
    "  question = state[\"question\"]\n",
    "\n",
    "  documents = retriever.get_relevant_documents(question)\n",
    "\n",
    "  return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "def generate(state):\n",
    "  \"\"\"\n",
    "  답변을 생성합니다\n",
    "\n",
    "  Args:\n",
    "      state (dict): 현재 그래프의 상태\n",
    "\n",
    "  Returns:\n",
    "      state (dict): LLM이 생성한 답변을 포함한 새로운 상태\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"---생성---\")\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "\n",
    "  generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "\n",
    "  return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "def grade_documents(state):\n",
    "  \"\"\"\n",
    "  검색된 문서가 질문과 연관이 있는지 평가합니다\n",
    "\n",
    "  Args:\n",
    "      state (dict): 현재 그래프의 상태\n",
    "\n",
    "  Returns:\n",
    "      state (dict): 연관이 있다고 판단된 문서가 업데이트된 상태\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"---문서와 질문의 연관성 평가---\")\n",
    "\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "\n",
    "  filtered_docs = []\n",
    "  web_search = \"아니오\"\n",
    "\n",
    "  for d in documents:\n",
    "    score = retrieval+grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "    grade = score.binary_score\n",
    "\n",
    "    if grade == \"예\":\n",
    "      print(\"---평가: 연관 문서---\")\n",
    "      filtered_docs.append(d)\n",
    "    else:\n",
    "      print(\"---평가: 연관 없는 문서---\")\n",
    "      web_search = \"예\"\n",
    "      continue\n",
    "\n",
    "  return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "\n",
    "def transform_query(state):\n",
    "  \"\"\"\n",
    "  질문을 더 적합한 형태로 변환합니다\n",
    "\n",
    "  Args:\n",
    "      state (dict): 현재 그래프의 상태\n",
    "\n",
    "  Returns:\n",
    "      state (dict): 변환된 질문이 업데이트된 상태\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"---질문 변환---\")\n",
    "\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "\n",
    "  better_question = question_rewriter.invoke({\"question\": question})\n",
    "\n",
    "  return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "def web_search(state):\n",
    "  \"\"\"\n",
    "  웹 검색을 수행합니다\n",
    "\n",
    "  Args:\n",
    "      state (dict): 현재 그래프의 상태\n",
    "\n",
    "  Returns:\n",
    "      state (dict): 웹 검색 결과가 업데이트된 상태\n",
    "  \"\"\"\n",
    "\n",
    "  print(\"---웹 검색---\")\n",
    "\n",
    "  question = state[\"question\"]\n",
    "  documents = state[\"documents\"]\n",
    "\n",
    "  docs = web_search_tool.invoke({\"query\": question})\n",
    "\n",
    "  web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "  web_results = Document(page_content=web_results)\n",
    "\n",
    "  documents.append(web_results)\n",
    "\n",
    "  return {\"documents\": documents, \"question\": question}"
   ],
   "metadata": {
    "id": "XbyTkHLi-tS0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}